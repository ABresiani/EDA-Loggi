{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f464587a",
   "metadata": {
    "id": "KJqp9AANOCtf",
    "papermill": {
     "duration": 0.010933,
     "end_time": "2024-10-31T22:48:19.793981",
     "exception": false,
     "start_time": "2024-10-31T22:48:19.783048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/media/logo/newebac_logo_black_half.png\" alt=\"ebac-logo\">\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff993f",
   "metadata": {
    "id": "QRcqbpLpFK5o",
    "papermill": {
     "duration": 0.00878,
     "end_time": "2024-10-31T22:48:19.812888",
     "exception": false,
     "start_time": "2024-10-31T22:48:19.804108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Análise Exploratória de Dados de Logística**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235c0e4",
   "metadata": {
    "id": "6-CvdKwqFPiW",
    "papermill": {
     "duration": 0.008741,
     "end_time": "2024-10-31T22:48:19.831633",
     "exception": false,
     "start_time": "2024-10-31T22:48:19.822892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1\\. Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497aee0",
   "metadata": {
    "id": "XRURE1uUFXGw",
    "papermill": {
     "duration": 0.008845,
     "end_time": "2024-10-31T22:48:19.849698",
     "exception": false,
     "start_time": "2024-10-31T22:48:19.840853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "O objetivo deste projeto é realizar uma análise exploratória dos dados fornecidos pela Loggi BUD, com o intuito de identificar insights que possam otimizar o processo logístico de entregas em Brasília, DF. Através de métodos de análise e visualização de dados, buscamos propor melhorias que possam beneficiar a eficiência e a experiência do cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe41a3",
   "metadata": {
    "id": "QxukLHaqFnkU",
    "papermill": {
     "duration": 0.008777,
     "end_time": "2024-10-31T22:48:19.867389",
     "exception": false,
     "start_time": "2024-10-31T22:48:19.858612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2\\. Pacotes e bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1764779e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T22:48:19.887464Z",
     "iopub.status.busy": "2024-10-31T22:48:19.886929Z",
     "iopub.status.idle": "2024-10-31T22:48:55.994949Z",
     "shell.execute_reply": "2024-10-31T22:48:55.993797Z"
    },
    "id": "VXUEW0VrF7XW",
    "outputId": "adbd3455-4db5-4395-d84f-4401542d7975",
    "papermill": {
     "duration": 36.121255,
     "end_time": "2024-10-31T22:48:55.997633",
     "exception": false,
     "start_time": "2024-10-31T22:48:19.876378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.10/site-packages (0.14.4)\r\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.9.6)\r\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (21.3)\r\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.2.3)\r\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (3.6.1)\r\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.8.5.post1)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2024.8.30)\r\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\r\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->geopandas) (3.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Instalando e importando as bibliotecas que serão utilizadas no projeto\n",
    "\n",
    "!pip3 install geopandas;\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import seaborn as sns\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed77bc3",
   "metadata": {
    "id": "irQxHW1zGkdZ",
    "papermill": {
     "duration": 0.009079,
     "end_time": "2024-10-31T22:48:56.016459",
     "exception": false,
     "start_time": "2024-10-31T22:48:56.007380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3\\. Exploração de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe6d9d",
   "metadata": {
    "id": "D7Cc-GXnVVN8",
    "papermill": {
     "duration": 0.011545,
     "end_time": "2024-10-31T22:48:56.039902",
     "exception": false,
     "start_time": "2024-10-31T22:48:56.028357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "É feita e extração do dado bruto e criado um arquivo chamado deliveries.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf61ddff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T22:48:56.065359Z",
     "iopub.status.busy": "2024-10-31T22:48:56.063999Z",
     "iopub.status.idle": "2024-10-31T22:49:17.864858Z",
     "shell.execute_reply": "2024-10-31T22:49:17.863311Z"
    },
    "id": "lxLj8e0GHAnr",
    "outputId": "c2267ab0-45e9-4058-df42-a1afec484206",
    "papermill": {
     "duration": 21.815387,
     "end_time": "2024-10-31T22:49:17.866675",
     "exception": true,
     "start_time": "2024-10-31T22:48:56.051288",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Os dados do arquivo são carregados em uma variável do tipo dicionário chamada 'data'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeliveries.json\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 5\u001b[0m   data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Transformando o dicionário em um DataFrame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m deliveries_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "!wget -q \"http://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/dataset/deliveries.json\" -O deliveries.json\n",
    "\n",
    "# Os dados do arquivo são carregados em uma variável do tipo dicionário chamada 'data'\n",
    "with open('deliveries.json', mode='r', encoding='utf8') as file:\n",
    "  data = json.load(file)\n",
    "\n",
    "# Transformando o dicionário em um DataFrame\n",
    "deliveries_df = pd.DataFrame(data)\n",
    "\n",
    "#Visualização dos dados\n",
    "deliveries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae064cbb",
   "metadata": {
    "id": "sTGDk_UmV-3s",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A coluna origin possui dados aninhados no formato JSON, portanto é feita a operação de achatamento para adiciona-la ao DataFrame principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7623ba",
   "metadata": {
    "id": "lzKOGfnBUAbo",
    "outputId": "7c3c8de1-8b46-47c4-e306-ab81d6a430ad",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# É feito o achatamento da coluna 'origin', criando um novo DataFrame chamado hub_origin_df\n",
    "hub_origin_df = pd.json_normalize(deliveries_df['origin'])\n",
    "\n",
    "# É feita a junção de ambos os DataFrames através do índice\n",
    "deliveries_df = pd.merge(left=deliveries_df, right=hub_origin_df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# A coluna 'origin' é descartada, e a ordem das colunas do DataFrame é organizada\n",
    "deliveries_df = deliveries_df.drop('origin', axis=1)\n",
    "deliveries_df = deliveries_df[['name', 'region', 'lng', 'lat', 'vehicle_capacity', 'deliveries']]\n",
    "\n",
    "# As colunas são renomeadas para ter mais clareza\n",
    "deliveries_df.rename(columns={'lng': 'hub_lng', 'lat': 'hub_lat'}, inplace=True)\n",
    "\n",
    "# Visualização dos dados\n",
    "deliveries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ed300",
   "metadata": {
    "id": "0xTIzFGTWL-Q",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A coluna deliveries contém uma lista de dados aninhados, serão feitos os processos de explosão e achatamento, e enfim os dados serão adicionados ao DataFrame principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc4435",
   "metadata": {
    "id": "MJKqVhTaUc80",
    "outputId": "10d462f2-5406-492d-9d56-521b997f403e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# É realizado o processo de explosão na coluna 'deliveries', criando o DataFrame deliveries_exploded_df\n",
    "deliveries_exploded_df = deliveries_df[['deliveries']].explode('deliveries')\n",
    "\n",
    "# É criado um novo DataFrame, organizando os dados que serão agregados ao DataFrame principal\n",
    "deliveries_normalized_df = pd.concat([\n",
    "    pd.DataFrame(deliveries_exploded_df['deliveries'].apply(lambda record: record['size'])).rename(columns={'deliveries': 'delivery_size'}),\n",
    "    pd.DataFrame(deliveries_exploded_df['deliveries'].apply(lambda record: record['point']['lng'])).rename(columns={'deliveries': 'delivery_lng'}),\n",
    "    pd.DataFrame(deliveries_exploded_df['deliveries'].apply(lambda record: record['point']['lat'])).rename(columns={'deliveries': 'delivery_lat'}),\n",
    "], axis= 1)\n",
    "\n",
    "# A coluna 'deliveries' é descartada, e os dados agregados em um único DataFrame\n",
    "deliveries_df = deliveries_df.drop('deliveries', axis = 1)\n",
    "deliveries_df = pd.merge(left=deliveries_df, right=deliveries_normalized_df, how='right', left_index=True, right_index=True)\n",
    "deliveries_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Visualização dos dados\n",
    "deliveries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3825f",
   "metadata": {
    "id": "issEsIx7XYBA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.1\\. Verificação da estrutura do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bba52",
   "metadata": {
    "id": "H1YaKiy1Xd3G",
    "outputId": "88fccea0-fa92-4bc5-cc81-5794977a5f79",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c48ca",
   "metadata": {
    "id": "-oB5bO9oXqIQ",
    "outputId": "1e2b8eb2-a86a-497c-a55f-ecc9803d678c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa806de",
   "metadata": {
    "id": "HLpj74-hX3UU",
    "outputId": "68c970be-cb5c-4e8c-8b64-d107e0b6cea1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71daa52",
   "metadata": {
    "id": "Gf0UFlVEX5qw",
    "outputId": "d84e813f-95ae-4730-ba41-58662cc6d30b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5b1c2",
   "metadata": {
    "id": "G3D0WReeYAUF",
    "outputId": "586eb70d-38ac-4fd9-8a96-f281cf550bc3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14a785",
   "metadata": {
    "id": "3t9HNlWmYPaG",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "O DataFrame principal contém um schema consiso e não possui valores nulos, portanto podemos prosseguir com a manipulação, enriquecimento e visualização dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a05ee",
   "metadata": {
    "id": "98hexQTyJS9I",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4\\. Manipulação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd49436",
   "metadata": {
    "id": "gREPcxCeZNT3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Primeiramente, será realizada a geocodificação reversa dos hubs, adicionando suas localizações ao DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48f9a9",
   "metadata": {
    "id": "DXU4Ee0QJS9Q",
    "outputId": "07f03b1b-8f65-4f98-b2be-20ba7f46d3d7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para o processo de geocodificação reversa dos hubs, colocamos seus dados em um DataFrame separado\n",
    "hub_df = deliveries_df[['region', 'hub_lng', 'hub_lat']]\n",
    "hub_df = hub_df.drop_duplicates().sort_values(by='region').reset_index(drop=True)\n",
    "\n",
    "geolocator = Nominatim(user_agent='ebac_geocoder')\n",
    "geocoder = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
    "\n",
    "# Os dados de latitude e longitude são concatenados, e é feita a geocodificação\n",
    "hub_df['coordinates'] = hub_df['hub_lat'].astype(str) + ', ' + hub_df['hub_lng'].astype(str)\n",
    "hub_df['geodata'] = hub_df['coordinates'].apply(geocoder)\n",
    "\n",
    "# Visualização dos dados\n",
    "hub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efbb460",
   "metadata": {
    "id": "yiXfnBnFfkQa",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Os dados na coluna 'geodata' estão em uma lista JSON, portanto iremos normalizar esta coluna, filtrar os dados necessários e adicioná-los ao DataFrame principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec006a",
   "metadata": {
    "id": "O5Fs9v6IgJ5W",
    "outputId": "c138e47d-72c2-4697-cb4f-ed992c4a49db",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# É feito o processo de normalização da coluna 'geodata'\n",
    "hub_geodata_df = pd.json_normalize(hub_df['geodata'].apply(lambda data: data.raw))\n",
    "\n",
    "# Os dados necessários são filtrados e propriamente nomeados para que o DataFrame possa ser lido com clareza\n",
    "hub_geodata_df = hub_geodata_df[['address.town', 'address.suburb', 'address.city']]\n",
    "hub_geodata_df.rename(columns={'address.town': 'hub_town', 'address.suburb': 'hub_suburb', 'address.city': 'hub_city'}, inplace=True)\n",
    "hub_geodata_df['hub_city'] = np.where(hub_geodata_df['hub_city'].notna(), hub_geodata_df['hub_city'], hub_geodata_df['hub_town'])\n",
    "hub_geodata_df['hub_suburb'] = np.where(hub_geodata_df['hub_suburb'].notna(), hub_geodata_df['hub_suburb'], hub_geodata_df['hub_city'])\n",
    "hub_geodata_df = hub_geodata_df.drop('hub_town', axis=1)\n",
    "\n",
    "# Os dados filtrados são adicionados ao DataFrame hub_df, e finalmente é feita a junção com o DataFrame principal, organizando as colunas\n",
    "hub_df = pd.merge(left=hub_df, right=hub_geodata_df, left_index=True, right_index=True)\n",
    "hub_df = hub_df[['region', 'hub_suburb', 'hub_city']]\n",
    "deliveries_df = pd.merge(left=deliveries_df, right=hub_df, how='inner', on='region')\n",
    "deliveries_df = deliveries_df[['name', 'region', 'hub_lng', 'hub_lat', 'hub_city', 'hub_suburb', 'vehicle_capacity', 'delivery_size', 'delivery_lng', 'delivery_lat']]\n",
    "\n",
    "# Visualização dos dados\n",
    "deliveries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff9641",
   "metadata": {
    "id": "m1dbXSQJhbrD",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Agora será feita a geocodificação reversa dos endereços de cada entrega, utilizando o arquivo csv providenciado pela EBAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a064a",
   "metadata": {
    "id": "nurXmXmhh0V4",
    "outputId": "3bc49818-1583-4494-ab7a-8e2107e1f8ee",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extração do dado bruto no arquivo csv fornecido\n",
    "!wget -q 'https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/dataset/deliveries-geodata.csv' -O deliveries-geodata.csv\n",
    "\n",
    "# Visualização dos dados\n",
    "deliveries_geodata_df = pd.read_csv('deliveries-geodata.csv')\n",
    "deliveries_geodata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f4fd6",
   "metadata": {
    "id": "ove1qnxUiYqo",
    "outputId": "5475ba68-06a9-4650-e3c1-b5a269ae9995",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Junção dos dados do arquivo csv com o DataFrame principal\n",
    "deliveries_df = pd.merge(left=deliveries_df, right=deliveries_geodata_df[['delivery_city', 'delivery_suburb']], how='inner', left_index=True, right_index=True)\n",
    "deliveries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2c951",
   "metadata": {
    "id": "_n4f2Wgii7Yp",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.1\\. Verificação da estrutura e qualidade do DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa673f",
   "metadata": {
    "id": "6X9-S2g4l6P5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Verificação de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe2a5c",
   "metadata": {
    "id": "OxlklFRpjUEC",
    "outputId": "5ba8e3bc-cb12-474e-91c2-831c1ac262b5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44eb3f6",
   "metadata": {
    "id": "4NzxV8x0l-i_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Confirmação de que apenas as colunas 'delivery_city' e 'delivery_suburb' possuem valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41726a",
   "metadata": {
    "id": "eGNkLOutjuCb",
    "outputId": "f48e8b99-6e3b-4c1c-eb54-df5f04f62fdd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71853c52",
   "metadata": {
    "id": "ThlFp-FDlOsB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Porcentagem dos dados nulos na coluna 'delivery_city'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1559663",
   "metadata": {
    "id": "Yp9Hb2elj5vJ",
    "outputId": "aadde746-123c-4932-c5db-d6cadf6836a1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "100 * (deliveries_df['delivery_city'].isna().sum() / len(deliveries_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ac9f4",
   "metadata": {
    "id": "dZyaIYGrlTjw",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Porcentagem de dados nulos na coluna 'delivery_suburb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19648354",
   "metadata": {
    "id": "X8oxaPebj8dW",
    "outputId": "6f3e9af6-bf9e-4e5d-f3f5-0d182c0eebe5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "100 * (deliveries_df['delivery_suburb'].isna().sum() / len(deliveries_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca117ac4",
   "metadata": {
    "id": "fKBtdtzhkMQn",
    "outputId": "4bd3b224-cc4e-4524-8cb4-1e04425f3ce9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_df = deliveries_df[['delivery_city']].value_counts() / len(deliveries_df)\n",
    "prop_df.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc67f7b",
   "metadata": {
    "id": "VPfGSn4wkOUH",
    "outputId": "c7557a09-b272-4e27-ef86-d3536aed65c9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_df = deliveries_df[['delivery_suburb']].value_counts() / len(deliveries_df)\n",
    "prop_df.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0604f",
   "metadata": {
    "id": "T1n4N0qTljOb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Conclusão:** há uma notável quandidade de valores nulos na coluna delivery_suburb, assim como Brasília sendo a cidade e bairro mais frequente, mesmo não sendo nenhum dos dois. Portanto, devido à estas discrepâncias, podemos presumir que os valores desta coluna não serão tão úteis para análise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9656555",
   "metadata": {
    "id": "KSgjP--1JS9R",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5\\. Visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25556988",
   "metadata": {
    "id": "PcBHis3tm7mm",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Para realizar a visualização dos dados obtidos até agora, será feito o download de mapas do Distrito Federal diretamente do site oficial do IBGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1cd10",
   "metadata": {
    "id": "Jlj3ACWCJS9R",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download dos mapas necessários\n",
    "!wget -q \"https://geoftp.ibge.gov.br/cartas_e_mapas/bases_cartograficas_continuas/bc100/go_df/versao2016/shapefile/bc100_go_df_shp.zip\" -O distrito-federal.zip\n",
    "!unzip -q distrito-federal.zip -d ./maps\n",
    "!cp ./maps/LIM_Unidade_Federacao_A.shp ./distrito-federal.shp\n",
    "!cp ./maps/LIM_Unidade_Federacao_A.shx ./distrito-federal.shx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cddd3",
   "metadata": {
    "id": "M6lhiBw1rCA6",
    "outputId": "ec8f8dd7-f931-4ecd-ea10-f90b16ed9028",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gerando a localização do Distrito Federal utilizando os arquivos\n",
    "mapa = geopandas.read_file(\"distrito-federal.shp\")\n",
    "mapa = mapa.loc[[0]]\n",
    "\n",
    "# Visualização dos dados\n",
    "mapa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e7802",
   "metadata": {
    "id": "BdgY5y-gq-EX",
    "outputId": "5b2250ba-aaab-46f3-c3d8-65ca843914bb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Com os arquivos, criaremos o DataFrame geo_hub_df, e a localização dos hubs estará na coluna 'geometry'\n",
    "hub_df = deliveries_df[['region', 'hub_lng', 'hub_lat']].drop_duplicates().reset_index(drop=True)\n",
    "geo_hub_df = geopandas.GeoDataFrame(hub_df, geometry=geopandas.points_from_xy(hub_df['hub_lng'], hub_df['hub_lat']))\n",
    "\n",
    "# Visualização dos dados\n",
    "geo_hub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee140bcf",
   "metadata": {
    "id": "fdhc8r6PpAOZ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "O mesmo processo será feito para a localização das entregas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2e299",
   "metadata": {
    "id": "8ts50-6zpDpi",
    "outputId": "8e19f80e-132f-4fe1-9372-61cfb29771a7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_deliveries_df = geopandas.GeoDataFrame(deliveries_df, geometry=geopandas.points_from_xy(deliveries_df['delivery_lng'], deliveries_df['delivery_lat']))\n",
    "\n",
    "# Visualização dos dados\n",
    "geo_deliveries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf2704a",
   "metadata": {
    "id": "u6lGzNxop0Xl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Utilizando o pacote\n",
    " matplotlib, será criada a vizualização dos hubs e suas respectivas entregas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea8809",
   "metadata": {
    "id": "bRKGR7DkqBhT",
    "outputId": "88ccf976-7e02-40ad-d268-b70aa152b98f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# É criado o plot vazio\n",
    "fi, ax = plt.subplots(figsize = (50/2.54, 50/2.54))\n",
    "\n",
    "# É criado o plot do mapa do Distrito Federal\n",
    "mapa.plot(ax=ax, alpha=0.4, color='lightgrey')\n",
    "\n",
    "# Criação do plot dos deliveries\n",
    "geo_deliveries_df.query('region == \"df-0\"').plot(ax=ax, markersize=1, color='red', label='df-0')\n",
    "geo_deliveries_df.query('region == \"df-1\"').plot(ax=ax, markersize=1, color='blue', label='df-1')\n",
    "geo_deliveries_df.query('region == \"df-2\"').plot(ax=ax, markersize=1, color='seagreen', label='df-2')\n",
    "\n",
    "# Plot dos hubs\n",
    "geo_hub_df.plot(ax=ax, markersize=30, marker='x', color='black', label='hub')\n",
    "\n",
    "# Plot da legenda\n",
    "plt.title('Entregas no Distrito Federal por Região', fontdict={'fontsize': 16})\n",
    "lgnd = plt.legend(prop={'size': 15})\n",
    "for handle in lgnd.legendHandles:\n",
    "  handle.set_sizes([50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c85291",
   "metadata": {
    "id": "W3Mp-jQfr8dM",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Proporção de entregas de cada hub no Distrito Federal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57e78d",
   "metadata": {
    "id": "VzU37gOEsFzE",
    "outputId": "d66f8dcc-73b3-4e1d-d906-27b31959999a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(deliveries_df[['region', 'vehicle_capacity']].value_counts(normalize=True)).reset_index()\n",
    "data.rename(columns={'proportion': 'region_percent'}, inplace=True)\n",
    "\n",
    "# Visualização dos dados\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c645f",
   "metadata": {
    "id": "sIsUcNZLsONq",
    "outputId": "4df32944-8c19-4efd-aa18-283ffed3b4ac",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilizando o pacote Seaborn, será criado um gráfico representando a proporção de entregas de cada hub\n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "  grafico = sns.barplot(data=data, x='region', y='region_percent', errorbar=None, palette='pastel')\n",
    "  grafico.set(title='Proporção de entregas por região', xlabel='Região', ylabel='Proporção');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba879c",
   "metadata": {
    "id": "-B3axWR_sbFW",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6\\. Conclusão / Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b0b4b",
   "metadata": {
    "id": "JShhEBzOs0mV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Após a realização do processo de análise exploratória de dados, e com a visualização do mapa e do grafico que foram gerados, podemos chegar aos seguintes insights:\n",
    "\n",
    "\n",
    "1.   As entregas de cada hub estão corretamente alocadas, e difícilmente entraram em conflito com outro hub;\n",
    "2.   Os hubs 0 e 2 têm que fazer entregas distantes, o que pode gerar aumento no tempo e preço de entrega, assim como afetar a manutenção dos veículos;\n",
    "3.   Juntos os hubs 1 e 2 estão encarregados de 89% das entregas. Como todos os veículos tem a mesma capacidade, pode-se pensar na possibilidade de deslocar alguns veículos do hub 0 para regiões de mais tráfego.\n",
    "\n",
    "Junto com estes insights, pode-se sugerir a possibilidade de realocação ou até mesmo criação de um novo hub para atender regiões mais distantes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.697131,
   "end_time": "2024-10-31T22:49:18.598134",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-31T22:48:16.901003",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
